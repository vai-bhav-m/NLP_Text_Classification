{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "bAL3SpM3LNR4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy.sparse import hstack\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jjljC8CgQGe_"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "def make_sub(predictions, filename='sub'):\n",
        "  sub = pd.DataFrame({\n",
        "      'uid': np.arange(len(predictions)),\n",
        "      'target_ind': predictions \n",
        "  })\n",
        "  sub.to_csv(filename + '.csv', index=False)\n",
        "  files.download(filename + '.csv') "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mx0JAX5gMWuB",
        "outputId": "60a5f17f-45d1-4db7-b968-90f0d2e40800"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "yyDXkbyeLlbr"
      },
      "outputs": [],
      "source": [
        "root = '/content/drive/MyDrive/Analytics Hack/'\n",
        "\n",
        "train = pd.read_csv(root + \"PS3_train.csv\")\n",
        "test = pd.read_csv(root + \"PS3_test.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "g4BuFK2bM8-l",
        "outputId": "bf8dee55-ca15-4eef-fa50-9c4df3f973be"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                             content  \\\n",
              "0  Premium quality five pocket jean from Wrangler...   \n",
              "1  If you're looking for a different kind of anim...   \n",
              "2  First things first: Yes, Thinking XXX features...   \n",
              "3  Feathertouch. 100% Polyester Machine Wash Warm...   \n",
              "4  When you need outstanding fuel delivery, easy ...   \n",
              "\n",
              "                                               title         uid  target_ind  \n",
              "0  Amazon.com: Wrangler Men's Rugged Wear Relaxed...  B0000CBALT         247  \n",
              "1  Sakura Diaries - Complete Series Collector's E...  B00005QFDT         453  \n",
              "2                 Thinking XXX (Extended Cut) (2006)  B000BNXD50         228  \n",
              "3  Amazon.com: Petite Feathertouch Pull-On Pant: ...  B0002LK9V2         223  \n",
              "4                            ACDelco EP386 Fuel Pump  B000C9PA54         312  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e939259b-269c-45ba-92a1-1e81ea5c82cd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>content</th>\n",
              "      <th>title</th>\n",
              "      <th>uid</th>\n",
              "      <th>target_ind</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Premium quality five pocket jean from Wrangler...</td>\n",
              "      <td>Amazon.com: Wrangler Men's Rugged Wear Relaxed...</td>\n",
              "      <td>B0000CBALT</td>\n",
              "      <td>247</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>If you're looking for a different kind of anim...</td>\n",
              "      <td>Sakura Diaries - Complete Series Collector's E...</td>\n",
              "      <td>B00005QFDT</td>\n",
              "      <td>453</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>First things first: Yes, Thinking XXX features...</td>\n",
              "      <td>Thinking XXX (Extended Cut) (2006)</td>\n",
              "      <td>B000BNXD50</td>\n",
              "      <td>228</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Feathertouch. 100% Polyester Machine Wash Warm...</td>\n",
              "      <td>Amazon.com: Petite Feathertouch Pull-On Pant: ...</td>\n",
              "      <td>B0002LK9V2</td>\n",
              "      <td>223</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>When you need outstanding fuel delivery, easy ...</td>\n",
              "      <td>ACDelco EP386 Fuel Pump</td>\n",
              "      <td>B000C9PA54</td>\n",
              "      <td>312</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e939259b-269c-45ba-92a1-1e81ea5c82cd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e939259b-269c-45ba-92a1-1e81ea5c82cd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e939259b-269c-45ba-92a1-1e81ea5c82cd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "train.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def clean_text(string):\n",
        "  out = re.sub(r'[^a-zA-Z0-9 ]', '', string)\n",
        "  return out\n",
        "\n",
        "train['content'] = train['content'].str.lower()\n",
        "train['content'] = train['content'].apply(clean_text)\n",
        "train['title'] = train['title'].str.lower()\n",
        "train['title'] = train['title'].apply(clean_text)\n",
        "\n",
        "test['content'] = test['content'].str.lower()\n",
        "test['content'] = test['content'].apply(clean_text)\n",
        "test['title'] = test['title'].str.lower()\n",
        "test['title'] = test['title'].apply(clean_text)"
      ],
      "metadata": {
        "id": "2sL4gQyRSXZm"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgDBpowyNG-a",
        "outputId": "20d07201-1139-41cb-b713-453ccbdeeae4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "348    1243\n",
              "351    1212\n",
              "349     622\n",
              "298     445\n",
              "91      439\n",
              "       ... \n",
              "14       35\n",
              "137      35\n",
              "377      35\n",
              "19       35\n",
              "170      35\n",
              "Name: target_ind, Length: 500, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "train.target_ind.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1tJ7sam6NM-b",
        "outputId": "888b0637-fcd8-4446-8c51-6faccc8ab4cf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(35112, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cm7TjCYDNPTI",
        "outputId": "82176d62-19bb-4426-b7b5-a54e1ab24ccc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8106, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAGA3rtSNWli",
        "outputId": "592e800e-3276-4213-c05c-f063da121bb6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2                           thinking xxx extended cut 2006\n",
              "1069                                      plain dirty 2002\n",
              "1289                            cathouse the specials 2010\n",
              "1477                      eight millimeter8mm 2 rated 1999\n",
              "2541                            nude showgirl championship\n",
              "3785                  latin dimes reggaeton mix vol 1 2006\n",
              "3929                      the ranch unrated and uncut 2004\n",
              "5197                      eight millimeter8mm 2 rated 1999\n",
              "5345                                  survival island 2006\n",
              "5722                               gun a car a blonde 1997\n",
              "5874                  rated x  a journey through porn 2005\n",
              "5954     pornography  the secret history of civilisatio...\n",
              "6618                                          gia vhs 1998\n",
              "7262            hot springs hotel the complete series 1995\n",
              "7934                                   bliss season 3 2004\n",
              "8437                                                 speed\n",
              "9343                                            flashpoint\n",
              "10683         nashville pussy  keep on fckin in paris 2003\n",
              "10890                 latin dimes reggaeton mix vol 1 2009\n",
              "12051                                  sex  the celts 2005\n",
              "12845                      the secret lives of adult stars\n",
              "15898              drivein cult classics  8 movie set 1970\n",
              "17362                     8mm2  eight millimeter pack 1999\n",
              "17741    fallen 2008 jessica drake alektra blue jenna h...\n",
              "18124               traci binghams fantasy fest uncensored\n",
              "18755                                 chronicles of nectar\n",
              "19591                        mommy xxx the complete series\n",
              "19918                                 a gun a car a blonde\n",
              "20163                              the boom boom show 2005\n",
              "24145            that tender touch vintage collection 2007\n",
              "24490                     8mm2  eight millimeter pack 1999\n",
              "26026        playboy playboys 50th anniversary celebration\n",
              "26676                  premium cuts bedtime fantasies 2003\n",
              "27584    stripped  exposing the business of baring it a...\n",
              "29177             dangerous babes 12 movie collection 2011\n",
              "29354              whos your daddy unrated widescreen 2005\n",
              "29645      sexual secrets  6 erotic movies on one dvd 2003\n",
              "30916                                     fairy tales 2005\n",
              "31182                        snoop doggs buckwild bus tour\n",
              "31757    xotic xtreme xgirls island adventure  hawaii 2003\n",
              "32168                        sex and the teenage mind 2002\n",
              "32883                       playboy no boys allowed 4 2006\n",
              "33711                             cathouse the series 2008\n",
              "34333                             animal attraction 3 2001\n",
              "34937                                  american swing 2008\n",
              "34961                bizarre lust of a sexual deviant 2001\n",
              "Name: title, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "train.title[train.target_ind == 228]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "PIc0wDP8YlxV"
      },
      "outputs": [],
      "source": [
        "\n",
        "# clf = CatBoostClassifier(iterations=60, learning_rate=0.2, max_depth=15, task_type=\"GPU\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "EXIuofPOWI_s"
      },
      "outputs": [],
      "source": [
        "df_t = train.sample(frac = 0.7).copy()\n",
        "df_v = train.drop(df_t.index).copy()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.feature_selection import chi2\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn import svm\n",
        "# from catboost import CatBoostClassifier\n",
        "from sklearn.decomposition import TruncatedSVD, NMF\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "import nltk\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvpnQClMHOQ7",
        "outputId": "123a8ace-ca86-478d-ec63-31a84c0ddcec"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aPYWpAZQMikq"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TF-IDF Vectorization with MultinomialNB model\n",
        "\n",
        "Inspiration: Haphazard model based on https://towardsdatascience.com/machine-learning-nlp-text-classification-using-scikit-learn-python-and-nltk-c52b92a7c73a\n",
        "\n",
        "\n",
        "ngram_range: (1,2)\n",
        "content_vec: 200,000\n",
        "title_vec: 100,000\n",
        "MultinomialNB with fit_prior: False\n",
        "\n",
        "Test score: ~43.79%\n",
        "\n",
        "Second place at ~42.96%"
      ],
      "metadata": {
        "id": "PIOE5mdYXROG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# stemmer = SnowballStemmer(\"english\", ignore_stopwords=True)\n",
        "stemmer = WordNetLemmatizer()\n",
        "class StemmedTfidfVectorizer(TfidfVectorizer):\n",
        "    def build_analyzer(self):\n",
        "        analyzer = super(StemmedTfidfVectorizer, self).build_analyzer()\n",
        "        return lambda doc: ([stemmer.lemmatize(w) for w in analyzer(doc)])"
      ],
      "metadata": {
        "id": "LjttzDgkhn21"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# content_vec = StemmedTfidfVectorizer(stop_words='english', ngram_range=(1,2), max_features=300_000)\n",
        "# title_vec = StemmedTfidfVectorizer(stop_words='english', ngram_range=(1,2), max_features=200_000)\n",
        "\n",
        "# content = content_vec.fit_transform(df_t.content)\n",
        "# title = title_vec.fit_transform(df_t.title)\n",
        "\n",
        "# y_train =  df_t.target_ind\n",
        "# X_train= hstack([content, title])\n",
        "\n",
        "# model = MultinomialNB(fit_prior=False, alpha=0.005)\n",
        "# model = model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "iLa4WliYL3-h"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "v00mpiRuQCvY"
      },
      "outputs": [],
      "source": [
        "# X_val = hstack([content_vec.transform(df_v.content), title_vec.transform(df_v.title)])\n",
        "# pred_t = model.predict(X_train)\n",
        "# pred_v = model.predict(X_val)\n",
        "\n",
        "# print(f\"Train acc = {np.mean(pred_t == df_t.target_ind)}\")\n",
        "# print(f\"Validation acc = {np.mean(pred_v == df_v.target_ind)}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tuning alpha\n",
        "content_vec = StemmedTfidfVectorizer(stop_words='english', ngram_range=(1,2), max_features=300_000)\n",
        "title_vec = StemmedTfidfVectorizer(stop_words='english', ngram_range=(1,2), max_features=200_000)\n",
        "\n",
        "content = content_vec.fit_transform(train.content)\n",
        "title = title_vec.fit_transform(train.title)\n",
        "\n",
        "y_train =  train.target_ind\n",
        "X_train= hstack([content, title])\n",
        "\n",
        "clf = MultinomialNB(fit_prior=False)\n",
        "\n",
        "nb_params = [{'alpha': [0.003, 0.004, 0.005, 0.006, 0.007]}]\n",
        "clf = GridSearchCV(clf, nb_params, cv = 5, scoring='accuracy')\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "print(clf.best_params_)\n",
        "print(clf.best_score_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BkkQeKLi0S83",
        "outputId": "62b0861c-c72a-4ca4-c338-b40d773ca43c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'alpha': 0.005}\n",
            "0.42851451225097437\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "With full data"
      ],
      "metadata": {
        "id": "MRYO6kgbr3vE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "content_vec = StemmedTfidfVectorizer(stop_words='english', ngram_range=(1,2), max_features=400_000)\n",
        "title_vec = StemmedTfidfVectorizer(stop_words='english', ngram_range=(1,2), max_features=150_000)\n",
        "\n",
        "content = content_vec.fit_transform(train.content)\n",
        "title = title_vec.fit_transform(train.title)\n",
        "\n",
        "y_train =  train.target_ind\n",
        "X_train= hstack([content, title])\n",
        "\n",
        "model = MultinomialNB(fit_prior=True, alpha=0.005)\n",
        "model = model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "Vwcuirlg90Ec"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_gsEkWnSWsmm",
        "outputId": "9f9d93de-43db-414d-e960-dc0e3c170550"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train acc = 0.7097288676236044\n"
          ]
        }
      ],
      "source": [
        "pred_t = model.predict(X_train)\n",
        "\n",
        "print(f\"Train acc = {np.mean(pred_t == y_train)}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = hstack([content_vec.transform(test.content), title_vec.transform(test.title)])\n",
        "\n",
        "predictions = model.predict(X_test)\n",
        "make_sub(predictions, filename='mnb_full_hypertuned')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "16ArHXS1sDEQ",
        "outputId": "243d0963-f72d-485f-de25-abd0266779a2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_6289b69a-114b-4eb2-a74a-870dca58d8b9\", \"mnb_full_hypertuned.csv\", 70293)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Word2vec "
      ],
      "metadata": {
        "id": "cOiPD0bKYPXg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "import gensim.downloader as gensim_api"
      ],
      "metadata": {
        "id": "iCG3Yd7IPXSI"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = train.target_ind.to_numpy()\n",
        "\n",
        "corpus = [] # list(train[\"content\"])\n",
        "corpus.extend(list(train[\"title\"]))\n",
        "\n",
        "## create list of lists of unigrams\n",
        "lst_corpus = []\n",
        "for string in corpus:\n",
        "   lst_words = string.split()\n",
        "   lst_grams = [\" \".join(lst_words[i:i+1]) \n",
        "               for i in range(0, len(lst_words), 1)]\n",
        "   lst_corpus.append(lst_grams)\n",
        "\n",
        "## detect bigrams and trigrams\n",
        "bigrams_detector = gensim.models.phrases.Phrases(lst_corpus, \n",
        "                 delimiter=\" \".encode(), min_count=5, threshold=10)\n",
        "bigrams_detector = gensim.models.phrases.Phraser(bigrams_detector)\n",
        "trigrams_detector = gensim.models.phrases.Phrases(bigrams_detector[lst_corpus], \n",
        "            delimiter=\" \".encode(), min_count=5, threshold=10)\n",
        "trigrams_detector = gensim.models.phrases.Phraser(trigrams_detector)"
      ],
      "metadata": {
        "id": "nqoopJ27PUCi"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit word2vec\n",
        "nlp = gensim.models.word2vec.Word2Vec(lst_corpus, size=15,   \n",
        "            window=8, min_count=1, sg=1, iter=30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfow5ix_NzX3",
        "outputId": "0e6b659c-2843-4649-c5a1-8fb42fe4760c"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:gensim.models.base_any2vec:consider setting layer size to a multiple of 4 for greater performance\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# for deep learning\n",
        "from tensorflow.keras import models, layers, preprocessing as kprocessing\n",
        "from tensorflow.keras import backend as K"
      ],
      "metadata": {
        "id": "Yuzcc9jgEYUL"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize text\n",
        "tokenizer = kprocessing.text.Tokenizer(lower=True, split=' ', \n",
        "                     oov_token=\"NaN\", \n",
        "                     filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n')\n",
        "tokenizer.fit_on_texts(lst_corpus)\n",
        "dic_vocabulary = tokenizer.word_index\n",
        "## create sequence\n",
        "lst_text2seq= tokenizer.texts_to_sequences(lst_corpus)\n",
        "## padding sequence\n",
        "X_train = kprocessing.sequence.pad_sequences(lst_text2seq, \n",
        "                    maxlen=100, padding=\"post\", truncating=\"post\")"
      ],
      "metadata": {
        "id": "WFL0paoZdK7L"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Same preparation for test set\n",
        "corpus = test[\"title\"]\n",
        "## create list of n-grams\n",
        "lst_corpus = []\n",
        "for string in corpus:\n",
        "    lst_words = string.split()\n",
        "    lst_grams = [\" \".join(lst_words[i:i+1]) for i in range(0, \n",
        "                 len(lst_words), 1)]\n",
        "    lst_corpus.append(lst_grams)\n",
        "    ## detect common bigrams and trigrams using the fitted detectors\n",
        "lst_corpus = list(bigrams_detector[lst_corpus])\n",
        "lst_corpus = list(trigrams_detector[lst_corpus])\n",
        "## text to sequence with the fitted tokenizer\n",
        "lst_text2seq = tokenizer.texts_to_sequences(lst_corpus)\n",
        "## padding sequence\n",
        "X_test = kprocessing.sequence.pad_sequences(lst_text2seq, maxlen=15,\n",
        "             padding=\"post\", truncating=\"post\")"
      ],
      "metadata": {
        "id": "QRn2Usd6dd0Y"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FzuFpxBNeDXM",
        "outputId": "38dc2eb4-90a7-4cbe-e44d-8052d1f395f5"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8106, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## start the matrix (length of vocabulary x vector size) with all 0s\n",
        "embeddings = np.zeros((len(dic_vocabulary)+1, 15))\n",
        "for word,idx in dic_vocabulary.items():\n",
        "  ## update the row with vector\n",
        "  try:\n",
        "    embeddings[idx] =  nlp[word]\n",
        "  ## if word not in model then skip and the row stays all 0s\n",
        "  except:\n",
        "    pass"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LRvtKVeOeMwY",
        "outputId": "b13d8880-451e-4e9a-b25c-48a763d62fc3"
      },
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-114-e05ce39095cf>:6: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  embeddings[idx] =  nlp[word]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRBLa9U4epQt",
        "outputId": "b47b1850-9fd8-4de0-a428-e8fe35806287"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11612, 15)"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word = \"plain\"\n",
        "print(\"dic[word]:\", dic_vocabulary[word], \"|idx\")\n",
        "print(\"embeddings[idx]:\", embeddings[dic_vocabulary[word]].shape, \n",
        "      \"|vector\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCQgpfUKevU4",
        "outputId": "0be66eb0-7c0d-4b57-91ff-25ccb7523ee3"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dic[word]: 4905 |idx\n",
            "embeddings[idx]: (15,) |vector\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## input\n",
        "x_in = layers.Input(shape=(15,))\n",
        "\n",
        "## embedding\n",
        "x = layers.Embedding(input_dim=embeddings.shape[0],  \n",
        "                     output_dim=embeddings.shape[1], \n",
        "                     weights=[embeddings],\n",
        "                     input_length=15, trainable=False)(x_in)\n",
        "                     \n",
        "## 2 layers of bidirectional lstm\n",
        "x = layers.Bidirectional(layers.LSTM(units=15, dropout=0.2, \n",
        "                         return_sequences=True))(x)\n",
        "x = layers.Bidirectional(layers.LSTM(units=15, dropout=0.2))(x)\n",
        "\n",
        "## final dense layers\n",
        "x = layers.Dense(64, activation='relu')(x)\n",
        "x = layers.Dense(128, activation='relu')(x)\n",
        "x = layers.Dense(256, activation='relu')(x)\n",
        "y_out = layers.Dense(500, activation='softmax')(x)## compile\n",
        "model = models.Model(x_in, y_out)\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpHc6ZEQe67k",
        "outputId": "5c791a4f-777f-4585-e890-ddcb48bbc6e2"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 15)]              0         \n",
            "                                                                 \n",
            " embedding_3 (Embedding)     (None, 15, 15)            174180    \n",
            "                                                                 \n",
            " bidirectional_6 (Bidirectio  (None, 15, 30)           3720      \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " bidirectional_7 (Bidirectio  (None, 30)               5520      \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 64)                1984      \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 128)               8320      \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 256)               33024     \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 500)               128500    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 355,248\n",
            "Trainable params: 181,068\n",
            "Non-trainable params: 174,180\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## encode y\n",
        "dic_y_mapping = {n:label for n,label in \n",
        "                 enumerate(np.unique(y_train))}\n",
        "inverse_dic = {v:k for k,v in dic_y_mapping.items()}\n",
        "y_train = np.array([inverse_dic[y] for y in y_train])\n",
        "\n",
        "## train\n",
        "training = model.fit(x=X_train, y=y_train, batch_size=256, \n",
        "                     epochs=10, shuffle=True, verbose=0, \n",
        "                     validation_split=0.3)\n",
        "\n",
        "## plot loss and accuracy\n",
        "metrics = [k for k in training.history.keys() if (\"loss\" not in k) and (\"val\" not in k)]\n",
        "fig, ax = plt.subplots(nrows=1, ncols=2, sharey=True, figsize=(18,6))\n",
        "\n",
        "ax[0].set(title=\"Training\")\n",
        "ax11 = ax[0].twinx()\n",
        "ax[0].plot(training.history['loss'], color='black')\n",
        "ax[0].set_xlabel('Epochs')\n",
        "ax[0].set_ylabel('Loss', color='black')\n",
        "for metric in metrics:\n",
        "    ax11.plot(training.history[metric], label=metric)\n",
        "ax11.set_ylabel(\"Score\", color='steelblue')\n",
        "ax11.legend()\n",
        "\n",
        "ax[1].set(title=\"Validation\")\n",
        "ax22 = ax[1].twinx()\n",
        "ax[1].plot(training.history['val_loss'], color='black')\n",
        "ax[1].set_xlabel('Epochs')\n",
        "ax[1].set_ylabel('Loss', color='black')\n",
        "for metric in metrics:\n",
        "     ax22.plot(training.history['val_'+metric], label=metric)\n",
        "ax22.set_ylabel(\"Score\", color=\"steelblue\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "pIJeKwcVfcrS",
        "outputId": "8e48421b-d7cd-4cc5-e747-699682e325f3"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-118-e65c9d827c72>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m## train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m training = model.fit(x=X_train, y=y_train, batch_size=256, \n\u001b[0m\u001b[1;32m      9\u001b[0m                      \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                      validation_split=0.3)\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1249, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1233, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1222, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\", line 1023, in train_step\n        y_pred = self(x, training=True)\n    File \"/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.8/dist-packages/keras/engine/input_spec.py\", line 295, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"model_3\" is incompatible with the layer: expected shape=(None, 15), found shape=(None, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## test\n",
        "predicted_prob = model.predict(X_test)\n",
        "predicted = [dic_y_mapping[np.argmax(pred)] for pred in \n",
        "             predicted_prob]"
      ],
      "metadata": {
        "id": "0LA5gUBTgGJv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Jk2KU_18hw0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### BERT\n",
        "\n",
        "Take lite, too much time on CPU"
      ],
      "metadata": {
        "id": "1KAPTZM74JnF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip install transformers"
      ],
      "metadata": {
        "id": "uZMxm0XN45se"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# from tqdm.notebook import tqdm\n",
        "\n",
        "# from transformers import BertTokenizer\n",
        "# from torch.utils.data import TensorDataset\n",
        "\n",
        "# from transformers import BertForSequenceClassification"
      ],
      "metadata": {
        "id": "x1KoXXn-4K4h"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# possible_labels = train.target_ind.unique()\n",
        "\n",
        "# label_dict = {}\n",
        "# for index, possible_label in enumerate(possible_labels):\n",
        "#     label_dict[possible_label] = index\n",
        "# label_dict\n",
        "\n",
        "# train['label'] = train.target_ind.replace(label_dict)"
      ],
      "metadata": {
        "id": "g63ZUxjm_PPD"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# df_t = train.sample(frac = 0.7).copy()\n",
        "# df_v = train.drop(df_t.index).copy()"
      ],
      "metadata": {
        "id": "DI9t60qp_2vF"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', \n",
        "#                                           do_lower_case=True)\n",
        "                                          \n",
        "# encoded_data_train = tokenizer.batch_encode_plus(\n",
        "#     df_t.title.values, \n",
        "#     add_special_tokens=True, \n",
        "#     return_attention_mask=True, \n",
        "#     pad_to_max_length=True, \n",
        "#     max_length=256, \n",
        "#     return_tensors='pt'\n",
        "# )\n",
        "\n",
        "# encoded_data_val = tokenizer.batch_encode_plus(\n",
        "#     df_v.title.values, \n",
        "#     add_special_tokens=True, \n",
        "#     return_attention_mask=True, \n",
        "#     pad_to_max_length=True, \n",
        "#     max_length=256, \n",
        "#     return_tensors='pt'\n",
        "# )\n",
        "\n",
        "\n",
        "# input_ids_train = encoded_data_train['input_ids']\n",
        "# attention_masks_train = encoded_data_train['attention_mask']\n",
        "# labels_train = torch.tensor(df_t.label.values)\n",
        "\n",
        "# input_ids_val = encoded_data_val['input_ids']\n",
        "# attention_masks_val = encoded_data_val['attention_mask']\n",
        "# labels_val = torch.tensor(df_v.label.values)\n",
        "\n",
        "# dataset_train = TensorDataset(input_ids_train, attention_masks_train, labels_train)\n",
        "# dataset_val = TensorDataset(input_ids_val, attention_masks_val, labels_val)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYOph2WN4kte",
        "outputId": "26c17c24-d405-4415-a8d1-3addc5a875a1"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:2339: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
        "#                                                       num_labels=len(train.label.values),\n",
        "#                                                       output_attentions=False,\n",
        "#                                                       output_hidden_states=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KzujFBfP7crw",
        "outputId": "286d93b8-dcb5-4acf-c043-f12b32a9ed2b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# batch_size = 4\n",
        "\n",
        "# dataloader_train = DataLoader(dataset_train, \n",
        "#                               sampler=RandomSampler(dataset_train), \n",
        "#                               batch_size=batch_size)\n",
        "\n",
        "# dataloader_validation = DataLoader(dataset_val, \n",
        "#                                    sampler=SequentialSampler(dataset_val), \n",
        "#                                    batch_size=batch_size)"
      ],
      "metadata": {
        "id": "EExoBNHW-Um-"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# from transformers import AdamW, get_linear_schedule_with_warmup\n",
        "\n",
        "# optimizer = AdamW(model.parameters(),\n",
        "#                   lr=1e-5, \n",
        "#                   eps=1e-8)\n",
        "                  \n",
        "# epochs = 5\n",
        "\n",
        "# scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "#                                             num_warmup_steps=0,\n",
        "#                                             num_training_steps=len(dataloader_train)*epochs)\n",
        "\n",
        "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gfVUWzq7-bHP",
        "outputId": "d1c63586-d886-4894-8dc4-d716e3bb6e13"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import random\n",
        "\n",
        "# seed_val = 42\n",
        "# random.seed(seed_val)\n",
        "# np.random.seed(seed_val)\n",
        "# torch.manual_seed(seed_val)\n",
        "# torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# def evaluate(dataloader_val):\n",
        "\n",
        "#     model.eval()\n",
        "    \n",
        "#     loss_val_total = 0\n",
        "#     predictions, true_vals = [], []\n",
        "    \n",
        "#     for batch in dataloader_val:\n",
        "        \n",
        "#         batch = tuple(b.to(device) for b in batch)\n",
        "        \n",
        "#         inputs = {'input_ids':      batch[0],\n",
        "#                   'attention_mask': batch[1],\n",
        "#                   'labels':         batch[2],\n",
        "#                  }\n",
        "\n",
        "#         with torch.no_grad():        \n",
        "#             outputs = model(**inputs)\n",
        "            \n",
        "#         loss = outputs[0]\n",
        "#         logits = outputs[1]\n",
        "#         loss_val_total += loss.item()\n",
        "\n",
        "#         logits = logits.detach().cpu().numpy()\n",
        "#         label_ids = inputs['labels'].cpu().numpy()\n",
        "#         predictions.append(logits)\n",
        "#         true_vals.append(label_ids)\n",
        "    \n",
        "#     loss_val_avg = loss_val_total/len(dataloader_val) \n",
        "    \n",
        "#     predictions = np.concatenate(predictions, axis=0)\n",
        "#     true_vals = np.concatenate(true_vals, axis=0)\n",
        "            \n",
        "#     return loss_val_avg, predictions, true_vals\n",
        "    \n",
        "# for epoch in tqdm(range(1, epochs+1)):\n",
        "    \n",
        "#     model.train()\n",
        "    \n",
        "#     loss_train_total = 0\n",
        "\n",
        "#     progress_bar = tqdm(dataloader_train, desc='Epoch {:1d}'.format(epoch), leave=False, disable=False)\n",
        "#     for batch in progress_bar:\n",
        "\n",
        "#         model.zero_grad()\n",
        "        \n",
        "#         batch = tuple(b.to(device) for b in batch)\n",
        "        \n",
        "#         inputs = {'input_ids':      batch[0],\n",
        "#                   'attention_mask': batch[1],\n",
        "#                   'labels':         batch[2],\n",
        "#                  }       \n",
        "\n",
        "#         outputs = model(**inputs)\n",
        "        \n",
        "#         loss = outputs[0]\n",
        "#         loss_train_total += loss.item()\n",
        "#         loss.backward()\n",
        "\n",
        "#         torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "#         optimizer.step()\n",
        "#         scheduler.step()\n",
        "        \n",
        "#         progress_bar.set_postfix({'training_loss': '{:.3f}'.format(loss.item()/len(batch))})\n",
        "         \n",
        "        \n",
        "#     torch.save(model.state_dict(), f'data_volume/finetuned_BERT_epoch_{epoch}.model')\n",
        "        \n",
        "#     tqdm.write(f'\\nEpoch {epoch}')\n",
        "    \n",
        "#     loss_train_avg = loss_train_total/len(dataloader_train)            \n",
        "#     tqdm.write(f'Training loss: {loss_train_avg}')\n",
        "    \n",
        "#     val_loss, predictions, true_vals = evaluate(dataloader_validation)\n",
        "#     tqdm.write(f'Validation loss: {val_loss}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "a4cdfe3699f14755bd21b41bc34696db",
            "fc1f221153ba4530be9256ead8990e03",
            "a57deb5a5dfd4ff5bf29f3891bd78ca9",
            "97aaad4c545043e3a5db1d7ff715c97a",
            "a7463ff64f09469ebb4da47a8ca8886b",
            "0af353c659b1446a898aceb54db28625",
            "8ae56a382ce344b5bd058cfce39092ae",
            "ddcbf62979f744d3896387daf4d26fab",
            "c56bb9a2606f460ba730a6f692f7c25b",
            "52e9ca0175704bfc9a1953f74c420b38",
            "35e5df2934f7485cb587ede8ca45c218",
            "5fe6c701a86b4e03af0fc343225b6b10",
            "fab48ce85c154e2a8290a331145de5bb",
            "156c2055ac8c4e7fbc7acdd1f60ab080",
            "779f44d58ea341f18b7436d61ab429d8",
            "fad034cff2c341389a6b5fa9673979f1",
            "acb12592994b45c1a5153230ffafead5",
            "402aeff8668b46d6857f50131487dd9d",
            "f8ea20c55515480e9036ac8b97aaa50b",
            "5b9190aa7385428ba4f85e08d4ac2f7d",
            "02de479bd9cb488a9b9953b014432bb3",
            "02c38192d0724325878f01697b56a303"
          ]
        },
        "id": "bcDY59C8-e02",
        "outputId": "e8375774-923d-4ef5-c1e0-aa6535527352"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a4cdfe3699f14755bd21b41bc34696db"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Epoch 1:   0%|          | 0/6145 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5fe6c701a86b4e03af0fc343225b6b10"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-b68da89e820e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0mloss_train_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    486\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m             )\n\u001b[0;32m--> 488\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    489\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    198\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W21XLZ6_DeDr"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a4cdfe3699f14755bd21b41bc34696db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fc1f221153ba4530be9256ead8990e03",
              "IPY_MODEL_a57deb5a5dfd4ff5bf29f3891bd78ca9",
              "IPY_MODEL_97aaad4c545043e3a5db1d7ff715c97a"
            ],
            "layout": "IPY_MODEL_a7463ff64f09469ebb4da47a8ca8886b"
          }
        },
        "fc1f221153ba4530be9256ead8990e03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0af353c659b1446a898aceb54db28625",
            "placeholder": "",
            "style": "IPY_MODEL_8ae56a382ce344b5bd058cfce39092ae",
            "value": "  0%"
          }
        },
        "a57deb5a5dfd4ff5bf29f3891bd78ca9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ddcbf62979f744d3896387daf4d26fab",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c56bb9a2606f460ba730a6f692f7c25b",
            "value": 0
          }
        },
        "97aaad4c545043e3a5db1d7ff715c97a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52e9ca0175704bfc9a1953f74c420b38",
            "placeholder": "",
            "style": "IPY_MODEL_35e5df2934f7485cb587ede8ca45c218",
            "value": " 0/5 [53:11&lt;?, ?it/s]"
          }
        },
        "a7463ff64f09469ebb4da47a8ca8886b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0af353c659b1446a898aceb54db28625": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ae56a382ce344b5bd058cfce39092ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ddcbf62979f744d3896387daf4d26fab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c56bb9a2606f460ba730a6f692f7c25b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "52e9ca0175704bfc9a1953f74c420b38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35e5df2934f7485cb587ede8ca45c218": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5fe6c701a86b4e03af0fc343225b6b10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fab48ce85c154e2a8290a331145de5bb",
              "IPY_MODEL_156c2055ac8c4e7fbc7acdd1f60ab080",
              "IPY_MODEL_779f44d58ea341f18b7436d61ab429d8"
            ],
            "layout": "IPY_MODEL_fad034cff2c341389a6b5fa9673979f1"
          }
        },
        "fab48ce85c154e2a8290a331145de5bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_acb12592994b45c1a5153230ffafead5",
            "placeholder": "",
            "style": "IPY_MODEL_402aeff8668b46d6857f50131487dd9d",
            "value": "Epoch 1:   4%"
          }
        },
        "156c2055ac8c4e7fbc7acdd1f60ab080": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8ea20c55515480e9036ac8b97aaa50b",
            "max": 6145,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5b9190aa7385428ba4f85e08d4ac2f7d",
            "value": 240
          }
        },
        "779f44d58ea341f18b7436d61ab429d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02de479bd9cb488a9b9953b014432bb3",
            "placeholder": "",
            "style": "IPY_MODEL_02c38192d0724325878f01697b56a303",
            "value": " 240/6145 [53:11&lt;22:26:58, 13.69s/it, training_loss=2.914]"
          }
        },
        "fad034cff2c341389a6b5fa9673979f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "acb12592994b45c1a5153230ffafead5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "402aeff8668b46d6857f50131487dd9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f8ea20c55515480e9036ac8b97aaa50b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5b9190aa7385428ba4f85e08d4ac2f7d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "02de479bd9cb488a9b9953b014432bb3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02c38192d0724325878f01697b56a303": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}